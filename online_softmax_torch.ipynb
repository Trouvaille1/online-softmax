{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6759a9b1-a71f-4f2d-b6f7-881d1c580261",
   "metadata": {},
   "source": [
    "# Online Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a81889-4e32-410f-9942-ae1e50197e73",
   "metadata": {},
   "source": [
    "github: xiaodongguaAIGC\n",
    "\n",
    "- softmax\n",
    "- Safe Softmax\n",
    "- online softmax\n",
    "- block online softmax\n",
    "- multi block online softmax\n",
    "- batch online softmax\n",
    "- multi block batch online softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5f591c-ac6d-4ddc-b7ef-b93d9e2187af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7e9c2d6-63ff-4e55-ad3a-f8bec54c8fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([-0.3, 0.2, 0.5, 0.7, 0.1, 0.8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e28e1fc-6bc2-4915-b2a5-04dc1b2b80dc",
   "metadata": {},
   "source": [
    "## Softmax By Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd32b22f-3dbe-45d2-ada1-74c13d3afe98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0827, 0.1364, 0.1841, 0.2249, 0.1234, 0.2485])\n"
     ]
    }
   ],
   "source": [
    "X_softmax = F.softmax(X, dim = 0)\n",
    "print(X_softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0398b98-93fa-4a6d-b206-4e0fe3678c34",
   "metadata": {},
   "source": [
    "## Softmax By Handwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8761f59c-1954-4052-95fa-7e9cced802f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0827, 0.1364, 0.1841, 0.2249, 0.1234, 0.2485])\n"
     ]
    }
   ],
   "source": [
    "X_exp_sum = X.exp().sum()\n",
    "X_softmax_hand = torch.exp(X) / X_exp_sum\n",
    "print(X_softmax_hand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81247fc4-f14b-4ce2-a715-9f1200d63225",
   "metadata": {},
   "source": [
    "## Safe Softmax By Handwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edba72aa-d000-4ae0-badc-1f9b171d9f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0827, 0.1364, 0.1841, 0.2249, 0.1234, 0.2485])\n"
     ]
    }
   ],
   "source": [
    "X_max = X.max()\n",
    "X_exp_sum_sub_max = torch.exp(X-X_max).sum()\n",
    "X_safe_softmax_hand = torch.exp(X - X_max) / X_exp_sum_sub_max\n",
    "print(X_safe_softmax_hand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01273773-397c-4b0d-9607-01b1de1dea45",
   "metadata": {},
   "source": [
    "## Online Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5f40da-622d-4745-b061-ccc392d32a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input x\n",
      "tensor([-0.3000,  0.2000,  0.5000,  0.7000,  0.1000,  0.8000])\n",
      "tensor([-0.3000,  0.2000,  0.5000,  0.7000,  0.1000])\n",
      "tensor(0.8000)\n",
      "online softmax result:  tensor([0.0827, 0.1364, 0.1841, 0.2249, 0.1234, 0.2485])\n"
     ]
    }
   ],
   "source": [
    "X_pre = X[:-1] #前N个数据\n",
    "print('input x')\n",
    "print(X)\n",
    "print(X_pre)\n",
    "print(X[-1])\n",
    "\n",
    "# we calculative t-1 time Online Softmax\n",
    "X_max_pre = X_pre.max()\n",
    "X_sum_pre = torch.exp(X_pre - X_max_pre).sum() #l_(N)\n",
    "\n",
    "# we calculative t time Online Softmax\n",
    "X_max_cur = torch.max(X_max_pre, X[-1]) # X[-1] is new data。更新全局最大值\n",
    "X_sum_cur = X_sum_pre * torch.exp(X_max_pre - X_max_cur) + torch.exp(X[-1] - X_max_cur) #l_(N+1)=l_N*exp(max_pre-max_cur) + exp(x_new-max_cur)，更新累加和\n",
    "\n",
    "# final we calculative online softmax\n",
    "X_online_softmax = torch.exp(X - X_max_cur) / X_sum_cur # 更新softmax\n",
    "print('online softmax result: ', X_online_softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b80860f-c775-4992-a580-a5c91e080670",
   "metadata": {},
   "source": [
    "## Block Online Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6ac9ff3-e6df-4cd9-8fd6-2d491e41da23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3000,  0.2000,  0.5000,  0.7000,  0.1000,  0.8000])\n",
      "(tensor([-0.3000,  0.2000,  0.5000]), tensor([0.7000, 0.1000, 0.8000]))\n"
     ]
    }
   ],
   "source": [
    "X_block = torch.split(X, split_size_or_sections = 3 , dim = 0) \n",
    "print(X)\n",
    "print(X_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83c30afc-84ac-4605-8a7f-f8360a6a3c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we parallel calculate  different block max & sum\n",
    "X_block_0_max = X_block[0].max()\n",
    "X_block_0_sum = torch.exp(X_block[0] - X_block_0_max).sum()\n",
    "\n",
    "X_block_1_max = X_block[1].max()\n",
    "X_block_1_sum = torch.exp(X_block[1] - X_block_1_max).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4e18507-5238-456e-956f-06568376b173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0827, 0.1364, 0.1841, 0.2249, 0.1234, 0.2485])\n"
     ]
    }
   ],
   "source": [
    "# parallel online block update max & sum\n",
    "X_max_global = torch.max(X_block_0_max, X_block_1_max) \n",
    "L_global = (X_block_0_sum * torch.exp(X_block_0_max - X_max_global) \\\n",
    "            + X_block_1_sum * torch.exp(X_block_1_max - X_max_global)) # block sum\n",
    "\n",
    "X_block_online_softmax_parallel = torch.exp(X - X_max_global) / L_global\n",
    "print(X_block_online_softmax_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f618de1-ec3d-4d14-a10b-77e291480249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0827, 0.1364, 0.1841, 0.2249, 0.1234, 0.2485])\n"
     ]
    }
   ],
   "source": [
    "# online block update max & sum\n",
    "# updated version for multi-block, simpler version\n",
    "X_block_1_max_update = torch.max(X_block_0_max, X_block_1_max) \n",
    "X_block_1_sum_update = X_block_0_sum * torch.exp(X_block_0_max - X_block_1_max_update) \\\n",
    "                     + torch.exp(X_block[1] - X_block_1_max_update).sum() # block sum\n",
    "\n",
    "X_block_online_softmax = torch.exp(X - X_block_1_max_update) / X_block_1_sum_update\n",
    "print(X_block_online_softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68937aa-1d6d-4f3a-a013-0ef6fb763607",
   "metadata": {},
   "source": [
    "## Multi Block Online Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a815125-e36d-4098-924c-abfbdac07fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3000,  0.2000,  0.5000,  0.7000,  0.1000,  0.8000])\n",
      "(tensor([-0.3000,  0.2000]), tensor([0.5000, 0.7000]), tensor([0.1000, 0.8000]))\n"
     ]
    }
   ],
   "source": [
    "X_block = torch.split(X, split_size_or_sections = 2, dim = 0) \n",
    "print(X)\n",
    "print(X_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26ed247b-2d4b-478a-a9d3-328cb23e0073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0827, 0.1364, 0.1841, 0.2249, 0.1234, 0.2485])\n",
      "tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "# online multi-block update max & sum\n",
    "M_old = torch.tensor([-100000.0])\n",
    "L_old = torch.tensor([0.0])\n",
    "\n",
    "# 在2.4我们实现了2个block的online softmax，我们可以拓展到多个块，并且使用for循环实现多block的更新\n",
    "for i in range(len(X_block)):\n",
    "    M = torch.max(X_block[i])\n",
    "    M_new = torch.max(M, M_old) \n",
    "    \n",
    "    L_new = L_old * torch.exp(M_old - M_new) \\\n",
    "            +  torch.exp(X_block[i] - M).sum() * torch.exp(M - M_new) \n",
    "    \n",
    "    # use simplest format\n",
    "    # L_new = L_old * torch.exp(M_old - M_new) \\\n",
    "    #         +  torch.exp(X_block[i] - M_new).sum() \n",
    "    \n",
    "    M_old = M_new\n",
    "    L_old = L_new\n",
    "\n",
    "X_multi_block_online_softmax = torch.exp(X - M_old) / L_old\n",
    "print(X_multi_block_online_softmax)\n",
    "print(X_multi_block_online_softmax.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0aadfb-df9a-4835-9945-b7c5b40bd995",
   "metadata": {},
   "source": [
    "## Batch Online Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c5288f-495e-415e-8a01-d9a683b489ef",
   "metadata": {},
   "source": [
    "### Batch Online Softmax by Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57e6e18e-4098-439e-8d97-094041d48f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0466,  0.9957, -0.7632,  1.5878, -0.5846,  2.0392],\n",
      "        [-0.2612, -1.0416, -0.8095,  0.6656,  1.2044,  0.3641],\n",
      "        [ 0.6272, -0.6707,  1.3326,  0.0887,  1.6424, -0.8036],\n",
      "        [-0.5737,  1.2376,  0.1689, -0.0404, -0.2656, -0.0805]])\n",
      "tensor([[0.0553, 0.1568, 0.0270, 0.2834, 0.0323, 0.4452],\n",
      "        [0.0929, 0.0426, 0.0537, 0.2348, 0.4024, 0.1736],\n",
      "        [0.1453, 0.0397, 0.2943, 0.0848, 0.4011, 0.0348],\n",
      "        [0.0718, 0.4395, 0.1509, 0.1224, 0.0977, 0.1176]])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "X_batch = torch.randn(4, 6)\n",
    "print(X_batch)\n",
    "X_batch_softmax = F.softmax(X_batch, dim = 1) \n",
    "print(X_batch_softmax)\n",
    "X_batch_softmax_evaluete = X_batch_softmax.sum(dim = 1)\n",
    "print(X_batch_softmax_evaluete) # row prob sum is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9821e291-a47a-48b8-9c63-2f39d4960867",
   "metadata": {},
   "source": [
    "### Batch Online Softmax by Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8abed75-6800-4cdb-be7b-a3a958a32256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3\n",
      "tensor([[-0.0466,  0.9957, -0.7632,  1.5878, -0.5846,  2.0392],\n",
      "        [-0.2612, -1.0416, -0.8095,  0.6656,  1.2044,  0.3641],\n",
      "        [ 0.6272, -0.6707,  1.3326,  0.0887,  1.6424, -0.8036],\n",
      "        [-0.5737,  1.2376,  0.1689, -0.0404, -0.2656, -0.0805]])\n",
      "tensor([[-0.0466,  0.9957, -0.7632],\n",
      "        [-0.2612, -1.0416, -0.8095],\n",
      "        [ 0.6272, -0.6707,  1.3326],\n",
      "        [-0.5737,  1.2376,  0.1689]])\n",
      "tensor([[ 1.5878, -0.5846,  2.0392],\n",
      "        [ 0.6656,  1.2044,  0.3641],\n",
      "        [ 0.0887,  1.6424, -0.8036],\n",
      "        [-0.0404, -0.2656, -0.0805]])\n"
     ]
    }
   ],
   "source": [
    "b, d = X_batch.shape\n",
    "print(b, d//2)\n",
    "\n",
    "# 二维分块（只拆分为两块，可以暂时不用for循环）\n",
    "X_batch_block_0 = X_batch[:, :d//2]\n",
    "X_batch_block_1 = X_batch[:, d//2:]\n",
    "\n",
    "print(X_batch)\n",
    "print(X_batch_block_0)\n",
    "print(X_batch_block_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c89f06f-5536-42ef-880e-55359005c1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9957],\n",
      "        [-0.2612],\n",
      "        [ 1.3326],\n",
      "        [ 1.2376]])\n",
      "tensor([[1.5249],\n",
      "        [2.0361],\n",
      "        [1.6288],\n",
      "        [1.5069]])\n"
     ]
    }
   ],
   "source": [
    "# we parallel calculate  different block max & sum\n",
    "X_batch_0_max, _ = X_batch_block_0.max(dim = 1, keepdim = True)\n",
    "X_batch_0_sum = torch.exp(X_batch_block_0 - X_batch_0_max).sum(dim = 1, keepdim = True)\n",
    "\n",
    "X_batch_1_max, _ = X_batch_block_1.max(dim = 1, keepdim = True)\n",
    "X_batch_1_sum = torch.exp(X_batch_block_1 - X_batch_1_max).sum(dim = 1, keepdim = True)\n",
    "\n",
    "print(X_batch_0_max)\n",
    "print(X_batch_0_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b97605a-4d38-40d1-bb90-c4243c608daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0553, 0.1568, 0.0270, 0.2834, 0.0323, 0.4452],\n",
      "        [0.0929, 0.0426, 0.0537, 0.2348, 0.4024, 0.1736],\n",
      "        [0.1453, 0.0397, 0.2943, 0.0848, 0.4011, 0.0348],\n",
      "        [0.0718, 0.4395, 0.1509, 0.1224, 0.0977, 0.1176]])\n"
     ]
    }
   ],
   "source": [
    "# online batch block update max & sum\n",
    "X_batch_1_max_update = torch.maximum(X_batch_0_max, X_batch_1_max) # 逐个元素找最大值\n",
    "X_batch_1_sum_update = X_batch_0_sum * torch.exp(X_batch_0_max - X_batch_1_max_update) \\\n",
    "                     + torch.exp(X_batch_block_1 - X_batch_1_max_update).sum(dim = 1, keepdim = True) # block sum\n",
    "\n",
    "X_batch_online_softmax = torch.exp(X_batch - X_batch_1_max_update) / X_batch_1_sum_update\n",
    "print(X_batch_online_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "540be634-264d-454f-a242-18cd0680ac38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0553, 0.1568, 0.0270, 0.2834, 0.0323, 0.4452],\n",
      "        [0.0929, 0.0426, 0.0537, 0.2348, 0.4024, 0.1736],\n",
      "        [0.1453, 0.0397, 0.2943, 0.0848, 0.4011, 0.0348],\n",
      "        [0.0718, 0.4395, 0.1509, 0.1224, 0.0977, 0.1176]])\n"
     ]
    }
   ],
   "source": [
    "X_batch_softmax_torch = F.softmax(X_batch, dim = 1) \n",
    "print(X_batch_softmax_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ec5c37-f50d-44bc-8643-14aeb69018e1",
   "metadata": {},
   "source": [
    "### Multi Block Batch Online Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19f1d55f-a943-460e-8fcf-04798b1d4423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-0.0466,  0.9957],\n",
      "        [-0.2612, -1.0416],\n",
      "        [ 0.6272, -0.6707],\n",
      "        [-0.5737,  1.2376]]), tensor([[-0.7632,  1.5878],\n",
      "        [-0.8095,  0.6656],\n",
      "        [ 1.3326,  0.0887],\n",
      "        [ 0.1689, -0.0404]]), tensor([[-0.5846,  2.0392],\n",
      "        [ 1.2044,  0.3641],\n",
      "        [ 1.6424, -0.8036],\n",
      "        [-0.2656, -0.0805]]))\n"
     ]
    }
   ],
   "source": [
    "# X_batch = torch.randn(4, 6)\n",
    "X_blocks = torch.split(X_batch, 2, dim=1)\n",
    "print(X_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2ff29eb-9d6b-43ae-b7af-d6bf6c594b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0553, 0.1568, 0.0270, 0.2834, 0.0323, 0.4452],\n",
      "        [0.0929, 0.0426, 0.0537, 0.2348, 0.4024, 0.1736],\n",
      "        [0.1453, 0.0397, 0.2943, 0.0848, 0.4011, 0.0348],\n",
      "        [0.0718, 0.4395, 0.1509, 0.1224, 0.0977, 0.1176]])\n",
      "tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]])\n"
     ]
    }
   ],
   "source": [
    "b, d = X_batch.shape\n",
    "M_old = torch.ones((b,1)) * -100000.0\n",
    "L_old = torch.zeros((b,1))\n",
    "\n",
    "for X_block in X_blocks:\n",
    "    M,_ = torch.max(X_block, dim = 1, keepdim = True)\n",
    "    M_new = torch.maximum(M, M_old) \n",
    "    \n",
    "    L_new = L_old * torch.exp(M_old - M_new) \\\n",
    "            + torch.exp(X_block - M_new).sum(dim = 1, keepdim = True) \n",
    "    \n",
    "    M_old = M_new\n",
    "    L_old = L_new\n",
    "\n",
    "X_blocks_batch = torch.exp(X_batch - M_old) / L_old\n",
    "print(X_blocks_batch)\n",
    "print(X_blocks_batch.sum(dim = 1, keepdim = True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
